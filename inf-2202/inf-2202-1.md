"Better data structures may be a luxry now, but they will be essential by the decade's end."

- Ideal cache model supports fine-grained data locality
- RAM Size M and block size B are known, goal is to minimize n block transfers.


- Data movement over computation (transfering data)
- i/O model: B-tree -> Search: Optimal memory transfer O(log bN)
- B tree works for 1 block size

- Ideal Cache model (CO)

- Num block transfers domainate exec time (transfer)
- M and B are unknown
- analysis for 2-level memory applicate for unknown mulit-level memory
- Temporal locality is exploidet perf<3
- Off-line replacement replacement is assumed: LRU (1+e)M memory is approx good as optimal M.
- CO layout: BFS
- Node idx: loc of node in mem

- Blocked lookup
- Loads multiple nodes
- vEB ~640x less I/O than BFS
- 1 mem transfer for each node after node 3 on search path
- log2N - log2B = theta(log2 N/B) ~theta(log2N) 

- Van Emde Boas layout
- CO model: O(log bN) mem transfers, B unknown


- Divide h/2 trees and repeat recursively

